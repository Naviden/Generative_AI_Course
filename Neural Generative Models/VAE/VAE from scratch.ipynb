{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b08fb2d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae3aa1f9",
   "metadata": {},
   "source": [
    "The following code provides a basic, function-based implementation of a VAE. Each function is commented to describe its purpose and how it contributes to the VAE model. In the last cell, the __train_step__ function ties everything together, showing how the data flows through the encoder, sampling process, and decoder, and how the loss is calculated. Remember, this is a simplified version for educational purposes, and in practice, you'd use more complex models and libraries for real-world applications."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc28fc9c",
   "metadata": {},
   "source": [
    "## Initializing weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bec31f9e",
   "metadata": {},
   "source": [
    "When initializing the weights and biases for the encoder and decoder in a Variational Autoencoder, we typically draw the initial weights from a normal distribution and set the biases to zero. Let $ \\mathbf{W}_{\\text{enc}} $ and $ \\mathbf{W}_{\\text{dec}} $ represent the weight matrices for the encoder and decoder, respectively, and $ \\mathbf{b}_{\\text{enc}} $ and $ \\mathbf{b}_{\\text{dec}} $ represent the bias vectors. The dimensions of these matrices and vectors are determined by the dimensions of the input data and the latent space:\n",
    "\n",
    "$$\n",
    "\\mathbf{W}_{\\text{enc}} \\sim \\mathcal{N}(0, 1), \\quad \\mathbf{W}_{\\text{enc}} \\in \\mathbb{R}^{\\text{input dim} \\times \\text{latentdim}}\n",
    "$$\n",
    "$$\n",
    "\\mathbf{b}_{\\text{enc}} = \\mathbf{0}, \\quad \\mathbf{b}_{\\text{enc}} \\in \\mathbb{R}^{\\text{latent dim}}\n",
    "$$\n",
    "$$\n",
    "\\mathbf{W}_{\\text{dec}} \\sim \\mathcal{N}(0, 1), \\quad \\mathbf{W}_{\\text{dec}} \\in \\mathbb{R}^{\\text{latent dim} \\times \\text{input dim}}\n",
    "$$\n",
    "$$\n",
    "\\mathbf{b}_{\\text{dec}} = \\mathbf{0}, \\quad \\mathbf{b}_{\\text{dec}} \\in \\mathbb{R}^{\\text{input dim}}\n",
    "$$\n",
    "\n",
    "This initialization process is an important step in setting up a neural network before starting the training process.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "729199d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_weights(input_dim, latent_dim):\n",
    "    \"\"\"\n",
    "    Initialize the weights and biases for the encoder and decoder.\n",
    "\n",
    "    :param input_dim: Dimensionality of the input data.\n",
    "    :param latent_dim: Dimensionality of the latent space.\n",
    "    :return: A tuple of weights and biases (enc_w, enc_b, dec_w, dec_b).\n",
    "    \"\"\"\n",
    "    enc_w = np.random.randn(input_dim, latent_dim)\n",
    "    enc_b = np.zeros(latent_dim)\n",
    "    dec_w = np.random.randn(latent_dim, input_dim)\n",
    "    dec_b = np.zeros(input_dim)\n",
    "    return enc_w, enc_b, dec_w, dec_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dcbcc6b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = 784  # Example input dimension\n",
    "latent_dim = 2   # Example latent dimension\n",
    "enc_w, enc_b, dec_w, dec_b = initialize_weights(input_dim, latent_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2d6fa408",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1568"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc_w.size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dd5ad89",
   "metadata": {},
   "source": [
    "## Encoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0498fc48",
   "metadata": {},
   "source": [
    "The encoder in a Variational Autoencoder maps the input data $ \\mathbf{x} $ to the parameters of a latent distribution. Specifically, it computes the mean $ \\boldsymbol{\\mu} $ and standard deviation $ \\boldsymbol{\\sigma} $ of the latent space distribution. The mean is computed as a linear transformation of the input data with a weight matrix $ \\mathbf{W}_{\\text{enc}} $ and a bias vector $ \\mathbf{b}_{\\text{enc}} $. For simplicity, the standard deviation is assumed to be fixed:\n",
    "\n",
    "$$\n",
    "\\boldsymbol{\\mu} = \\mathbf{x} \\mathbf{W}_{\\text{enc}} + \\mathbf{b}_{\\text{enc}}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\boldsymbol{\\sigma} = \\mathbf{1}\n",
    "$$\n",
    "\n",
    "Where $ \\mathbf{1} $ denotes a vector of ones with the appropriate dimension.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "06aa1ddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encoder(x, enc_w, enc_b):\n",
    "    \"\"\"\n",
    "    The encoder function that maps the input to the latent space.\n",
    "\n",
    "    :param x: Input data.\n",
    "    :param enc_w: Encoder weights.\n",
    "    :param enc_b: Encoder biases.\n",
    "    :return: Mean (mu) and standard deviation (sigma) of the latent space distribution.\n",
    "    \"\"\"\n",
    "    mu = np.dot(x, enc_w) + enc_b\n",
    "    sigma = np.ones(mu.shape)  # Assuming a fixed standard deviation\n",
    "    return mu, sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d0e82155",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.random.randn(100, input_dim)  # Random input data\n",
    "mu, sigma = encoder(x, enc_w, enc_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8314d044",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 31.84215112,  18.4446171 ],\n",
       "       [-12.92450276,  64.99140038],\n",
       "       [  3.03866093,   2.22427563],\n",
       "       [ -4.11366312,  16.58756981],\n",
       "       [ -4.39058369, -10.62579385],\n",
       "       [ 43.97913981,  18.74311296],\n",
       "       [-12.94964908,  22.09646499],\n",
       "       [-34.9839025 ,  83.54324054],\n",
       "       [  8.46465696, -24.45603504],\n",
       "       [-42.66305087,   4.8495479 ],\n",
       "       [-17.01702975, -24.45242835],\n",
       "       [ 44.15808078,  17.68679119],\n",
       "       [-13.61595207,  18.65836144],\n",
       "       [ 28.41908738,  70.18911245],\n",
       "       [-19.44315722,  34.4889411 ],\n",
       "       [-29.00803889, -53.72001225],\n",
       "       [-24.81433463, -10.9910458 ],\n",
       "       [-15.28726885,  -0.10059178],\n",
       "       [ 11.74361542, -35.46596385],\n",
       "       [ 41.8495574 ,  48.58975048],\n",
       "       [-37.5564656 , -20.4067944 ],\n",
       "       [ 15.57921759,  37.22530866],\n",
       "       [ 16.72871821,  11.93798056],\n",
       "       [  4.24876049,  -4.56299685],\n",
       "       [ 20.41127361,   6.14363229],\n",
       "       [ 41.89709087,   6.07309175],\n",
       "       [ 46.38195749, -26.68483984],\n",
       "       [ -8.41520311,  -2.11857207],\n",
       "       [-30.8866103 ,  39.35193953],\n",
       "       [ -1.53140024,  -1.00768732],\n",
       "       [-22.23392472, -30.77489537],\n",
       "       [ 44.51476286, -12.08352062],\n",
       "       [  7.64305221, -16.23646635],\n",
       "       [  3.29186633,  23.43614747],\n",
       "       [-46.12737384,   7.47902901],\n",
       "       [ -5.85061397, -29.87393583],\n",
       "       [-18.98129619,  22.85074505],\n",
       "       [-14.49382541, -20.70706074],\n",
       "       [ 10.07165754, -11.35228403],\n",
       "       [  2.96193243,  64.45819169],\n",
       "       [-15.96133051,   3.92955178],\n",
       "       [-20.17260346,   9.76442461],\n",
       "       [ 19.73426893,  21.54864225],\n",
       "       [-24.14613525,   5.10033245],\n",
       "       [ 42.4520695 , -16.72799282],\n",
       "       [-39.04218059,  22.58248959],\n",
       "       [  6.24495793,   7.78225225],\n",
       "       [  7.93144254, -43.91285926],\n",
       "       [ -8.40970854, -10.81725539],\n",
       "       [  4.46044006,  29.96568209],\n",
       "       [-45.78155319,   4.38088425],\n",
       "       [  6.34325124,  56.89848888],\n",
       "       [-40.51287371, -33.33799841],\n",
       "       [ 40.34104964,  51.32303913],\n",
       "       [ 32.74679669, -51.14443544],\n",
       "       [  7.89186925,  -2.09440554],\n",
       "       [ -6.96734681,  -8.05681605],\n",
       "       [  5.04262842,   1.41332072],\n",
       "       [-54.54979898,  -5.35987868],\n",
       "       [-43.29712975,  19.90735642],\n",
       "       [  3.39031605, -13.74681809],\n",
       "       [ 57.63243187,  -7.47461365],\n",
       "       [  8.97671583,  -1.01040695],\n",
       "       [ 12.71657349,   1.87344794],\n",
       "       [ 20.51927865,  -4.39193181],\n",
       "       [ 30.70069604,   8.53989855],\n",
       "       [ -8.31138189,  -7.84031523],\n",
       "       [-31.57405379, -33.04055066],\n",
       "       [  5.09057821,   5.24937572],\n",
       "       [ 54.28060208,  65.2767122 ],\n",
       "       [ 42.67017984, -13.31011402],\n",
       "       [ 35.48936943, -48.51190713],\n",
       "       [-11.58877519, -22.0055889 ],\n",
       "       [ 41.46464875,  -8.69822381],\n",
       "       [ 15.5555199 ,  18.56649571],\n",
       "       [-12.35416103, -33.89277148],\n",
       "       [ 12.13799828,  -9.75947152],\n",
       "       [-29.06104757, -44.1851486 ],\n",
       "       [-43.24391435,  -9.06462928],\n",
       "       [  3.70268874,  24.66499776],\n",
       "       [ 28.13771677, -48.01464613],\n",
       "       [ 12.2176778 ,  -0.82305869],\n",
       "       [  1.42405996,  -1.46478327],\n",
       "       [  7.2893045 ,   0.7463152 ],\n",
       "       [-26.33605148, -40.47714826],\n",
       "       [ 18.96959444,   4.07920464],\n",
       "       [ -0.1907898 ,  -0.6276731 ],\n",
       "       [-23.95460315,  15.08996084],\n",
       "       [-12.96621617, -16.4627437 ],\n",
       "       [  8.73217284,  -5.67703938],\n",
       "       [-13.01537742,  20.51100335],\n",
       "       [ 41.1855007 ,  47.6555796 ],\n",
       "       [-38.25846836,  62.36195808],\n",
       "       [ -1.41464702, -67.37069651],\n",
       "       [-32.02407167,   7.57482176],\n",
       "       [ -3.08536372,  18.26890878],\n",
       "       [ 18.33736963,  30.19560085],\n",
       "       [ -7.05514387, -15.57326353],\n",
       "       [-24.47183034,   8.94524444],\n",
       "       [-12.3163019 ,  49.70376033]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15206dbf",
   "metadata": {},
   "source": [
    "## Sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35424d33",
   "metadata": {},
   "source": [
    "In the VAE, a random sample $ \\boldsymbol{\\epsilon} $ is drawn from a standard normal distribution. This sample is then scaled by the standard deviation $ \\boldsymbol{\\sigma} $ and shifted by the mean $ \\boldsymbol{\\mu} $ to produce the latent variable $ \\mathbf{z} $:\n",
    "\n",
    "$$\n",
    "\\mathbf{z} = \\boldsymbol{\\mu} + \\boldsymbol{\\sigma} \\cdot \\boldsymbol{\\epsilon}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "60ab40da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sampling(mu, sigma):\n",
    "    \"\"\"\n",
    "    Sampling function to sample from the latent space distribution.\n",
    "\n",
    "    :param mu: Mean of the latent space distribution.\n",
    "    :param sigma: Standard deviation of the latent space distribution.\n",
    "    :return: Sampled latent variable.\n",
    "    \"\"\"\n",
    "    eps = np.random.randn(*mu.shape)\n",
    "    return mu + sigma * eps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b8a7f376",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = sampling(mu, sigma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9f006cb7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 32.72153578,  17.23722627],\n",
       "       [-12.63093904,  63.74864285],\n",
       "       [  2.45277016,   1.85457519],\n",
       "       [ -4.67685513,  17.19637801],\n",
       "       [ -3.52709133,  -8.81530127],\n",
       "       [ 43.65871159,  19.55955331],\n",
       "       [-14.2537434 ,  24.05102122],\n",
       "       [-35.39905019,  82.74305034],\n",
       "       [  7.54047792, -24.21408225],\n",
       "       [-42.30888159,   4.23175032],\n",
       "       [-18.42457295, -25.83420253],\n",
       "       [ 44.77847584,  14.87898252],\n",
       "       [-12.53948338,  17.59151684],\n",
       "       [ 29.26408463,  72.17314733],\n",
       "       [-19.15289944,  34.20912149],\n",
       "       [-29.58152732, -53.28987589],\n",
       "       [-24.40759222, -11.99700683],\n",
       "       [-16.15816136,   1.10963132],\n",
       "       [ 12.37632705, -35.77236487],\n",
       "       [ 40.86027632,  49.89172566],\n",
       "       [-38.48876469, -20.40126653],\n",
       "       [ 14.3180555 ,  37.5147953 ],\n",
       "       [ 14.77285301,  12.20697339],\n",
       "       [  6.59755417,  -3.38227218],\n",
       "       [ 21.42864232,   6.22135028],\n",
       "       [ 40.9090912 ,   6.97801677],\n",
       "       [ 47.5154429 , -26.13530575],\n",
       "       [ -7.85087574,  -1.73965643],\n",
       "       [-31.65725584,  39.49073542],\n",
       "       [ -3.88029463,  -1.53235694],\n",
       "       [-22.73067929, -31.19366026],\n",
       "       [ 42.81113975, -12.84130786],\n",
       "       [  7.80450193, -16.5627686 ],\n",
       "       [  3.01542694,  22.61556594],\n",
       "       [-45.84323453,   7.86591101],\n",
       "       [ -6.08719806, -28.92604908],\n",
       "       [-17.64211257,  23.23499138],\n",
       "       [-12.72341153, -20.88766881],\n",
       "       [  9.27304711, -10.90278245],\n",
       "       [  3.62133727,  67.35902023],\n",
       "       [-15.40280543,   3.03075465],\n",
       "       [-19.90146283,   9.83311403],\n",
       "       [ 19.79041187,  21.5846953 ],\n",
       "       [-25.2718806 ,   5.26762837],\n",
       "       [ 43.40245042, -16.46560504],\n",
       "       [-39.49158958,  23.23402626],\n",
       "       [  5.97359708,   8.30843445],\n",
       "       [  8.46591012, -43.01718223],\n",
       "       [ -9.79347882, -12.07579338],\n",
       "       [  4.02653169,  29.79638293],\n",
       "       [-46.48709314,   4.26133475],\n",
       "       [  6.18138639,  56.18075852],\n",
       "       [-41.53104711, -31.4208169 ],\n",
       "       [ 39.10131961,  51.25300145],\n",
       "       [ 32.3728932 , -51.15223644],\n",
       "       [  9.44345861,  -1.967119  ],\n",
       "       [ -7.22013218,  -8.26458854],\n",
       "       [  4.68336324,  -0.17921051],\n",
       "       [-54.36314588,  -7.48360216],\n",
       "       [-43.53593732,  19.96949394],\n",
       "       [  3.34893772, -13.65791927],\n",
       "       [ 56.28261813,  -7.74957813],\n",
       "       [  7.03478737,   0.28392023],\n",
       "       [  9.8953136 ,   1.28787271],\n",
       "       [ 18.53320129,  -4.58246405],\n",
       "       [ 31.92939796,   6.47242603],\n",
       "       [ -7.95364748,  -8.86986521],\n",
       "       [-30.87576905, -31.02782172],\n",
       "       [  3.89875745,   3.82065842],\n",
       "       [ 55.79672236,  63.79273875],\n",
       "       [ 43.01336494, -13.91156102],\n",
       "       [ 35.80445984, -47.60593092],\n",
       "       [-11.98064004, -22.0324925 ],\n",
       "       [ 43.02245028,  -9.71003856],\n",
       "       [ 15.75841386,  18.88034653],\n",
       "       [-13.64984329, -32.54889177],\n",
       "       [ 12.07107799, -12.6487913 ],\n",
       "       [-28.78352735, -44.30513521],\n",
       "       [-43.82978989,  -8.86821411],\n",
       "       [  2.73767151,  24.56165274],\n",
       "       [ 28.22199148, -48.67680404],\n",
       "       [ 14.11061894,  -1.22107877],\n",
       "       [ -0.11718346,  -2.42292428],\n",
       "       [  6.12507841,   0.25277927],\n",
       "       [-24.84117679, -40.21346455],\n",
       "       [ 19.71700308,   3.75774518],\n",
       "       [  0.40516496,  -1.60942595],\n",
       "       [-24.03194953,  15.10559298],\n",
       "       [-12.81635154, -17.18862021],\n",
       "       [  9.96235892,  -6.09448034],\n",
       "       [-13.26263795,  20.81618643],\n",
       "       [ 39.67550693,  46.60960648],\n",
       "       [-38.97684393,  61.69520321],\n",
       "       [ -2.85810688, -69.84405229],\n",
       "       [-32.47859864,   9.7289791 ],\n",
       "       [ -2.65905766,  17.66785892],\n",
       "       [ 18.6314571 ,  30.41896346],\n",
       "       [ -5.35175208, -12.79284496],\n",
       "       [-25.15265587,   9.66176377],\n",
       "       [-12.307763  ,  49.6100549 ]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5c951c9",
   "metadata": {},
   "source": [
    "## Decoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea683a8d",
   "metadata": {},
   "source": [
    "The output of the decoder is calculated as the dot product of the latent variable $ \\mathbf{z} $ and the decoder weights $ \\mathbf{W}_{\\text{dec}} $, plus the decoder bias $ \\mathbf{b}_{\\text{dec}} $:\n",
    "\n",
    "$$\n",
    "\\mathbf{o} = \\mathbf{z} \\mathbf{W}_{\\text{dec}} + \\mathbf{b}_{\\text{dec}}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "979202ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decoder(z, dec_w, dec_b):\n",
    "    \"\"\"\n",
    "    The decoder function that maps the latent space back to the input space.\n",
    "\n",
    "    :param z: Sampled latent variable.\n",
    "    :param dec_w: Decoder weights.\n",
    "    :param dec_b: Decoder biases.\n",
    "    :return: Reconstructed input.\n",
    "    \"\"\"\n",
    "    return np.dot(z, dec_w) + dec_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1ae34d26",
   "metadata": {},
   "outputs": [],
   "source": [
    "recon_x = decoder(sample, dec_w, dec_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "87a7a856",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ -35.28206563,  -82.83484423,   31.90688011, ...,   41.09382012,\n",
       "          13.83334433,   42.99562771],\n",
       "       [-163.22330987,  -61.14319342,  106.54160504, ...,  -56.9769415 ,\n",
       "          14.85357888,   15.896075  ],\n",
       "       [  -4.05761783,   -6.95319401,    3.34134047, ...,    2.7518588 ,\n",
       "           1.19827091,    3.48251245],\n",
       "       ...,\n",
       "       [  30.82310001,   26.73971919,  -22.05664065, ...,   -0.89659981,\n",
       "          -5.12322392,  -11.63526597],\n",
       "       [ -30.43088138,   33.36960826,   14.15481005, ...,  -44.96856069,\n",
       "          -4.06176446,  -22.47570235],\n",
       "       [-127.62966993,  -43.0355889 ,   82.69961257, ...,  -48.21488702,\n",
       "          10.88602279,    9.71674577]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recon_x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5abb5f0",
   "metadata": {},
   "source": [
    "## Loss Function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef9d840a",
   "metadata": {},
   "source": [
    "The loss function for the VAE consists of two parts: the reconstruction loss and the KL divergence. The reconstruction loss is calculated as the mean squared error between the original input $x $ and the reconstructed input $ \\hat{x} $:\n",
    "\n",
    "$$\n",
    "\\text{recon loss} = \\frac{1}{n} \\sum_{i=1}^{n} (x_i - \\hat{x}_i)^2\n",
    "$$\n",
    "\n",
    "The KL divergence loss is calculated using the mean $ \\mu $ and the standard deviation $ \\sigma $ of the latent space distribution:\n",
    "\n",
    "$$\n",
    "\\text{KL loss} = -\\frac{1}{2} \\sum_{i=1}^{n} \\left(1 + \\log(\\sigma_i^2) - \\mu_i^2 - \\sigma_i^2\\right)\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "26b0c71b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_function(x, recon_x, mu, sigma):\n",
    "    \"\"\"\n",
    "    Loss function for the VAE, combining reconstruction loss and KL divergence.\n",
    "\n",
    "    :param x: Original input data.\n",
    "    :param recon_x: Reconstructed input data.\n",
    "    :param mu: Mean of the latent space distribution.\n",
    "    :param sigma: Standard deviation of the latent space distribution.\n",
    "    :return: Total loss value.\n",
    "    \"\"\"\n",
    "    recon_loss = np.mean((x - recon_x) ** 2)\n",
    "    kl_loss = -0.5 * np.sum(1 + np.log(sigma**2) - mu**2 - sigma**2)\n",
    "    return recon_loss + kl_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cb6a0b64",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = loss_function(x, recon_x, mu, sigma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "609ce956",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "79382.41793811017"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52610661",
   "metadata": {},
   "source": [
    "A training step in a Variational Autoencoder involves several stages. Given an input $ \\mathbf{x} $, the encoder generates parameters $ \\boldsymbol{\\mu} $ and $ \\boldsymbol{\\sigma} $ for the latent distribution:\n",
    "\n",
    "$$\n",
    "\\boldsymbol{\\mu}, \\boldsymbol{\\sigma} = \\text{encoder}(\\mathbf{x}, \\mathbf{W}_{\\text{enc}}, \\mathbf{b}_{\\text{enc}})\n",
    "$$\n",
    "\n",
    "A latent variable $ \\mathbf{z} $ is then sampled from this distribution:\n",
    "\n",
    "$$\n",
    "\\mathbf{z} = \\text{sampling}(\\boldsymbol{\\mu}, \\boldsymbol{\\sigma})\n",
    "$$\n",
    "\n",
    "This latent variable is passed through the decoder to produce a reconstruction $ \\hat{\\mathbf{x}} $ of the original input:\n",
    "\n",
    "$$\n",
    "\\hat{\\mathbf{x}} = \\text{decoder}(\\mathbf{z}, \\mathbf{W}_{\\text{dec}}, \\mathbf{b}_{\\text{dec}})\n",
    "$$\n",
    "\n",
    "The loss for this training step is computed as a combination of the reconstruction error between $ \\mathbf{x} $ and $ \\hat{\\mathbf{x}} $, and a regularization term from the KL divergence between the latent distribution and the prior:\n",
    "\n",
    "$$\n",
    "\\mathcal{L} = \\text{loss function}(\\mathbf{x}, \\hat{\\mathbf{x}}, \\boldsymbol{\\mu}, \\boldsymbol{\\sigma})\n",
    "$$\n",
    "\n",
    "This loss $ \\mathcal{L} $ is then used to update the model parameters $ \\mathbf{W}_{\\text{enc}}, \\mathbf{b}_{\\text{enc}}, \\mathbf{W}_{\\text{dec}}, \\mathbf{b}_{\\text{dec}} $ through backpropagation and an optimization algorithm.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e2ec8bd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(x, enc_w, enc_b, dec_w, dec_b):\n",
    "    \"\"\"\n",
    "    A single training step for the VAE.\n",
    "\n",
    "    :param x: Input data for training.\n",
    "    :param enc_w: Encoder weights.\n",
    "    :param enc_b: Encoder biases.\n",
    "    :param dec_w: Decoder weights.\n",
    "    :param dec_b: Decoder biases.\n",
    "    :return: Loss value for the current training step.\n",
    "    \"\"\"\n",
    "    mu, sigma = encoder(x, enc_w, enc_b)\n",
    "    z = sampling(mu, sigma)\n",
    "    recon_x = decoder(z, dec_w, dec_b)\n",
    "    return loss_function(x, recon_x, mu, sigma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "37f003d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 77914.00597357837\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "input_dim = 784  # Example input dimension\n",
    "latent_dim = 2   # Example latent dimension\n",
    "enc_w, enc_b, dec_w, dec_b = initialize_weights(input_dim, latent_dim)\n",
    "x = np.random.randn(100, input_dim)  # Random input data\n",
    "loss = train_step(x, enc_w, enc_b, dec_w, dec_b)\n",
    "print(f\"Loss: {loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4076afa0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
